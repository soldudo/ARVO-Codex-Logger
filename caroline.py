import logging
import subprocess
import json
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Optional
from queries import get_context
from arvo_tools import initial_setup

logging.basicConfig(
    level=logging.INFO,
    format='[APP] %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)

vuln_list = [40096184, 42488087, 42513136, 42530547, 424242614]
project_list = ['skia', 'wolfssl', 'binutils-preconditions', 'opensc', 'libxml2']
fuzz_target = [
    './out/android_codec tmp/poc', # 40096184
    './out/fuzzer-wolfssl-server-randomize tmp/poc', # 42488087
    './out/fuzz_objdump_safe tmp/poc', # 42513136
    './out/fuzz_pkcs11 tmp/poc', # 42530547
    './out/schema tmp/poc' # 424242614
]
crash_type_list = [
    'Heap-buffer-overflow WRITE 4',
    'Heap-buffer-overflow WRITE 1', # 42488087
    'Heap-double-free', # 42513136
    'Stack-buffer-overflow READ 8', # 42530547
    'Heap-buffer-overflow WRITE 1' # 424242614
]

experiment_no = 1  # Change this index to run different experiments
# vuln = f'arvo-{vuln_list[experiment_no]}-vul' # 

# vuln = 'arvo_42530547_1766869583-vul'

project = project_list[experiment_no]
crash_type = crash_type_list[experiment_no]

# crash_original = 'crash_arvo-424242614-vul-1766980840.log' # get this from arvo_tools

# crash_original = 'crash_42530547.log'
# patch1_crash = 'runs/arvo-42513136-vul-1766251130/crash_log_patch1.txt'


# path to crash log generated by fuzzing with poc
# crash_path = Path(__file__).parent / vuln / "crash_report.log"



# workspace_list = [
#     '',
#     f'{vuln}/src/wolfssl', # 42488087
#     f'{vuln}/src/binutils-preconditions', # 42513136
#     f'{vuln}/src/opensc', # 42530547
#     'arvo-424242614-vul-1766980840/src/libxml2' # 424242614
# ]

# prompt += 'The correct fix addresses a problem in the function fuzz_display_file2 in ada_nm.h at line 239, and two problems in the function fuzz_display_object_bfd in ada_objdump.h at lines 95 and 114. Use this information to reattempt the fix.'

# prompt_initial = f'Find and fix the bug in {project} to remove the {crash_type} shown in the log below. Provide the lines of code and file locations changed in this task.\n{crash_log}\n'
# prompt_fail = f'Your previous fix did not remove the crash. Review the new crash log'

def conduct_run(vuln: str, container: str, prompt: str, workspace: Path):
    run_timestamp = int(time.time())
    log_path = Path(__file__).parent / "runs" / container / f"{vuln}-{run_timestamp}.log"

    log_path.parent.mkdir(parents=True, exist_ok=True)

    command = ['codex', 'exec', '--json', '--full-auto', '--cd', str(workspace), 'resume', '019b3597-268f-7c90-9a60-fb713ee6104f', prompt]

    # command = ['codex', 'exec', '--json', '--full-auto', '--cd', str(workspace), prompt]
    
    # command_initial = ['codex', 'exec', '--json', '--full-auto', '--cd', str(workspace), prompt]
    # command_retry = ['codex', 'exec', '--json', '--full-auto', '--cd', str(workspace), 'resume', '--last', prompt]

    


    print("using command:", command)
    print(f'Logging to {log_path}\n')
    
    start_time = time.time()
    duration = 0.0
    return_code = None

    with open(log_path, 'w', encoding='utf-8') as log_file:
        metadata = {
            'vuln': vuln,
            'workspace': str(workspace),
            'command': command,
            'timestamp_iso': datetime.now().isoformat(),
            'timestamp_unix': start_time,
            'prompt': prompt
        }

        log_file.write(json.dumps(metadata) + '\n')
        log_file.flush()

        process = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            bufsize=1
        )


        try:
            for line in process.stdout:
                line = line.rstrip('\n')
                if not line.strip():
                    continue

                log_entry = {
                    'log_type': 'stream_output',
                    'timestamp_iso': datetime.now().isoformat(),
                    'timestamp_unix': time.time(),
                    'data': None
                }

                try:
                    event = json.loads(line)
                    log_entry['data'] = event

                    msg_type = event.get('type')

                    # Case 1: Command Execution Result
                    if msg_type == 'item.completed' and event.get('item', {}).get('type') == 'command_execution':
                        item = event['item']
                        raw_output = item.get('aggregated_output', '')
                        exit_code = item.get('exit_code')
                        print(f"\n[Command Result - Exit {exit_code}]:\n{raw_output}")

                    # Case 2: Reasoning (Thinking)
                    elif msg_type == 'item.completed' and event.get('item', {}).get('type') == 'reasoning':
                        text = event['item'].get('text', '').replace('**', '')
                        print(f"\n[Thinking]: {text}")
                    
                    # Case 3: Executing Command
                    elif msg_type == 'item.started' and event.get('item', {}).get('type') == 'command_execution':
                        print(f"\n> [Executing]: {event['item'].get('command')}")

                    # Case 4: Final Message
                    elif msg_type == 'item.completed' and event.get('item', {}).get('type') =='agent_message':
                        text = event['item'].get('text', '')
                        print(f"\n[agent_message]: {text}")



                except json.JSONDecodeError:
                    print(f'Non-JSON output: {line}')
                    log_entry['data'] = {'raw_text': line}
                    continue
                
                log_file.write(json.dumps(log_entry) + '\n')
                log_file.flush()
                # Consider adding timestamp to log entries by writing wrapped json
                # timed_event = {
                #     'timestamp': time.time(),
                #     'event': event
                # }

                
            return_code = process.wait()
            end_time = time.time()
            duration = end_time - start_time


            stderr_output = process.stderr.read()
            if stderr_output:
                print('\nCodex stderr output:\n', stderr_output)
                log_file.write(json.dumps({
                    'log_type': 'stderr_output',
                    'timestamp_iso': datetime.now().isoformat(),
                    'timestamp_unix': time.time(),
                    'data': stderr_output
                }) + '\n')
                # log_file.flush() # copilot rec
            
            print(f'Codex finished with return code {return_code} in {duration:.2f} seconds.')

        except Exception as e:
            print(f'Error during execution: {e}')
            log_file.write(json.dumps({
                'log_type': 'execution_error',
                'timestamp_iso': datetime.now().isoformat(),
                'timestamp_unix': time.time(),
                'data': str(e)
            }) + '\n')
            raise e
                
        finally:
            meta_end = {
                'log_type': 'session_end',
                'timestamp_iso': datetime.now().isoformat(),
                'timestamp_unix': time.time(),
                'duration_seconds': duration,
                'return_code': return_code
            }
            log_file.write(json.dumps(meta_end) + '\n')
            log_file.close()

if __name__ == "__main__":
    # container, crash_original = initial_setup(vuln_list[experiment_no])

    # manually enter info when errors encountered
    # errors happen often when extracting tar due to /dev file operations not permitted
    # these errors should not affect agent's work fixing vulnerabilities
    
    container = 'arvo-42488087-vul-1767071807'
    # crash_original = 'crash_arvo-40096184-vul-1767039350.log'
    # crash_path = Path(__file__).parent / crash_original

    crash_first_patch = Path(__file__).parent / 'runs' / container / 'crash_first_patch.log'
    crash_path = Path(__file__).parent / 'runs' / container / 'crash_first_patch.log'

    try:
        with open(crash_path, "r", encoding="utf-8", errors="replace") as f:
            crash_log = f.read()
    except FileNotFoundError:
        print(f"Error: The file {crash_path} was not found.")

    workspace = Path(__file__).parent / container / 'src' / project_list[experiment_no]

    prompt = 'Your previous fixes did not remove the crash as indicated by this new crash log:'
    prompt += f'<crash_log>{crash_log}</crash_log>'
    prompt += 'The workspace has been reset with the original files. A known correct fix made changes to the following files:' 
    prompt += 'src/internal.c around lines 21167 - 21171, 23224, 25164 and 25176; wolfcrypt/src/dh.c near lines 1212, 1244, 1284 and 1289; and wolfcrypt/test/test.c near lines 14644, 14766 and 14812.' 
    prompt += 'Use this information to reattempt the fix.'

    # prompt = f'Find and fix the bug in {project} to remove the {crash_type} shown in the log below. Provide the lines of code and file locations changed in this task.'
    




    conduct_run(vuln_list[experiment_no], container, prompt, workspace)